# Day 4

## Readme

1. Review [docker-compose.yml](https://github.com/dbt-labs/dbt-spark/blob/main/docker-compose.yml) from `dbt-spark` adapter
    * How are all things composed together?
    * Spark 3.1.1 only?!
1. Use [spark-testing](https://github.com/dbt-labs/dbt-spark#running-locally) profile from`dbt-spark` adapter
1. [dbt Models](https://docs.getdbt.com/docs/building-a-dbt-project/building-models)
1. [Profile Setup](https://github.com/databricks/dbt-databricks) for the dbt-databricks plugin
1. Review [CONTRIBUTING](https://github.com/dbt-labs/dbt-core/blob/HEAD/CONTRIBUTING.md)
1. Read up on [dbt init](https://docs.getdbt.com/reference/commands/init) (esp. [profile_template.yml](https://docs.getdbt.com/reference/commands/init#profile_templateyml))
